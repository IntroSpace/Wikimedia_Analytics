# Система аналитики правок Wikimedia в реальном времени

Этот проект представляет собой полноценный конвейер для сбора, обработки и отображения данных в реальном времени на примере потока правок из проектов Wikimedia (Wikipedia, Wiktionary и т.д.).

Проект демонстрирует совместную работу **Kafka**, **Redis**, **FastAPI** и **Docker** для создания асинхронной и масштабируемой системы.

---

## Архитектура

Поток данных в системе организован следующим образом:

```
[Поток Wikimedia] -> [producer.py] -> [Kafka] -> [consumer.py] -> [Redis] -> [api.py] -> [dashboard.py]
```

1.  **producer.py** подписывается на публичный поток событий Wikimedia и отправляет каждую правку как сообщение в топик Kafka.
2.  **consumer.py** читает сообщения из Kafka, агрегирует их (считает количество правок по доменам) и сохраняет результат в Redis.
3.  **api.py** предоставляет REST API для получения посчитанной статистики из Redis.
4.  **dashboard.py** обращается к API и выводит статистику в консоль в виде таблицы, обновляя её в реальном времени.

---

## Технологический стек

* **Бэкенд:** Python 3
* **Брокер сообщений:** Apache Kafka
* **In-memory база данных:** Redis
* **Веб-фреймворк API:** FastAPI
* **Контейнеризация:** Docker, Docker Compose
* **Python-библиотеки:** `kafka-python`, `redis`, `fastapi`, `uvicorn`, `requests`, `rich`, `sseclient-py`

---

## Описание файлов

* `consumer.py`
    * **Потребитель Kafka.** Читает события из топика `wikimedia_events`, подсчитывает количество правок для каждого домена (например, `en.wikipedia.org`) и сохраняет счетчики в Redis.
* `producer.py`
    * **Продюсер Kafka.** Подключается к потоку событий Wikimedia, получает данные о правках и отправляет их в топик Kafka `wikimedia_events`.
* `api.py`
    * **API-сервер на FastAPI.** Предоставляет эндпоинт `/stats`, который по запросу забирает данные о статистике из Redis и отдает их в формате JSON.
* `dashboard.py`
    * **Консольный дашборд.** Запускает в терминале приложение, которое каждые 10 секунд опрашивает API, получает актуальную статистику и выводит её в виде красиво отформатированной таблицы.
* `requirements.txt`
    * Список всех необходимых Python-зависимостей для проекта.
* `docker-compose.yml`
    * Файл конфигурации для Docker Compose. Описывает и запускает сервисы Kafka, Zookeeper и Redis в изолированных контейнерах.
* `run.sh`
    * Главный управляющий скрипт для удобного запуска и остановки всех компонентов проекта.

---

## Запуск проекта

### Предварительные требования

Перед запуском убедитесь, что у вас установлены:
* **Python 3.8+**
* **Docker** и **Docker Compose**

### Пошаговая инструкция

1.  **Клонируйте репозиторий**
    ```bash
    git clone https://github.com/IntroSpace/Wikimedia_Analytics
    cd Wikimedia_Analytics
    ```

2.  **Сделайте скрипт `run.sh` исполняемым**
    Эта команда даёт разрешение на запуск скрипта. Её нужно выполнить только один раз.
    ```bash
    chmod +x run.sh
    ```

3.  **Первоначальная настройка**
    Эта команда создаст виртуальное окружение `venv`, установит все зависимости из `requirements.txt` и запустит Docker-контейнеры с Kafka и Redis в фоновом режиме.
    ```bash
    ./run.sh setup
    ```

4.  **Запустите все компоненты**
    Каждую следующую команду нужно запускать **в отдельном окне терминала**.

    * **Терминал 1: Запуск Продюсера** (отправляет данные в Kafka)
        ```bash
        ./run.sh producer
        ```
    * **Терминал 2: Запуск Потребителя** (обрабатывает данные и кладет в Redis)
        ```bash
        ./run.sh consumer
        ```
    * **Терминал 3: Запуск API** (предоставляет доступ к данным)
        ```bash
        ./run.sh api
        ```
    * **Терминал 4: Запуск Дашборда** (отображает статистику)
        ```bash
        ./run.sh dashboard
        ```

    После выполнения этих шагов в последнем терминале вы увидите таблицу со статистикой, которая обновляется каждые 10 секунд.

5.  **Остановка проекта**
    Когда вы закончили работу, вы можете остановить все Docker-контейнеры одной командой:
    ```bash
    ./run.sh stop
    ```
    Это остановит и удалит контейнеры Kafka и Redis. Остальные скрипты можно остановить в их терминалах с помощью `Ctrl+C`.
